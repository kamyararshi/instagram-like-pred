{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate profiles data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  alias  numberPosts  numberFollowers  numberFollowing  \\\n",
      "0            1misssmeis          988           720979              233   \n",
      "1                3ala2o          938           792886              466   \n",
      "2                   433         6009         14545102              433   \n",
      "3        6senseofficial         3324           243094                0   \n",
      "4               7ikhals         1444           219458              221   \n",
      "..                  ...          ...              ...              ...   \n",
      "973             _ingo_1          422           149566              127   \n",
      "974  _mariannejacobsen_         1593           189279              290   \n",
      "975             _picolo          776           927457              566   \n",
      "976          _tinamaria          821           160393              730   \n",
      "977              _tuck4         1623           139150              246   \n",
      "\n",
      "                                               website  \n",
      "0                                    www.sylviemeis.de  \n",
      "1                  www.youtube.com/watch?v=MXkqzeIlhSQ  \n",
      "2                                    onelink.to/q6w524  \n",
      "3                      www.facebook.com/6senseofficial  \n",
      "4                                 instagram.com/ikhals  \n",
      "..                                                 ...  \n",
      "973                                               None  \n",
      "974                          www.delicate-photoart.com  \n",
      "975                             www.patreon.com/picolo  \n",
      "976  jewelrybyad.com/da/jewelry-for-a-good-cause-20...  \n",
      "977                                   takashiyasui.com  \n",
      "\n",
      "[978 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the folder path\n",
    "folder_path = \"profiles\"\n",
    "\n",
    "# Initialize empty lists to store the extracted data\n",
    "alias_list = []\n",
    "number_posts_list = []\n",
    "number_followers_list = []\n",
    "number_following_list = []\n",
    "website_list = []\n",
    "\n",
    "# Iterate over the JSON files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        # Read the JSON file with UTF-8 encoding\n",
    "        with open(os.path.join(folder_path, filename), encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract the required attributes\n",
    "        alias = data.get(\"alias\")\n",
    "        number_posts = data.get(\"numberPosts\")\n",
    "        number_followers = data.get(\"numberFollowers\")\n",
    "        number_following = data.get(\"numberFollowing\")\n",
    "        website = data.get(\"website\")\n",
    "        \n",
    "        # Append the data to the respective lists\n",
    "        alias_list.append(alias)\n",
    "        number_posts_list.append(number_posts)\n",
    "        number_followers_list.append(number_followers)\n",
    "        number_following_list.append(number_following)\n",
    "        website_list.append(website)\n",
    "\n",
    "# Create the data frame\n",
    "data = {\n",
    "    \"alias\": alias_list,\n",
    "    \"numberPosts\": number_posts_list,\n",
    "    \"numberFollowers\": number_followers_list,\n",
    "    \"numberFollowing\": number_following_list,\n",
    "    \"website\": website_list\n",
    "}\n",
    "profiles_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the data frame\n",
    "print(profiles_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate posts data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            alias                                           urlImage  isVideo  \\\n",
      "0      1misssmeis  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "1      1misssmeis  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "2      1misssmeis  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "3      1misssmeis  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "4      1misssmeis  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "...           ...                                                ...      ...   \n",
      "16534      _tuck4  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "16535      _tuck4  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "16536      _tuck4  [https://scontent.cdninstagram.com/t51.2885-15...    False   \n",
      "16537      _tuck4  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "16538      _tuck4  https://scontent.cdninstagram.com/t51.2885-15/...    False   \n",
      "\n",
      "       multipleImage                                    tags  \\\n",
      "0              False                      [#exclusivspezial]   \n",
      "1              False               [#jumpsuit, #glam, #ootn]   \n",
      "2              False       [#rehearsalday, #behindthescenes]   \n",
      "3              False                 [#dress, #shoes, #glam]   \n",
      "4              False  [#weekend, #yay, #happyweekend, #kiss]   \n",
      "...              ...                                     ...   \n",
      "16534          False                              [#RECO_ig]   \n",
      "16535          False                              [#RECO_ig]   \n",
      "16536           True                                 [#film]   \n",
      "16537          False                              [#RECO_ig]   \n",
      "16538          False                              [#RECO_ig]   \n",
      "\n",
      "                                                mentions  \\\n",
      "0      [@fraukeludowig_official, @rtl_exclusiv, @tine...   \n",
      "1      [@tine, @rachelzoe, @lecolook, @letsdance, @rt...   \n",
      "2               [@letsdance, @rtlde, @rtlde, @letsdance]   \n",
      "3      [@bydanienl, @roland_mouret, @casadeiofficial,...   \n",
      "4                [@elisabettafranchi, @serenagoldenbaum]   \n",
      "...                                                  ...   \n",
      "16534                                         [@reco_ig]   \n",
      "16535                                         [@reco_ig]   \n",
      "16536                                                 []   \n",
      "16537                                         [@reco_ig]   \n",
      "16538                                         [@reco_ig]   \n",
      "\n",
      "                                             description  \\\n",
      "0      With my lovely colleague @fraukeludowig_offici...   \n",
      "1      My look last night, hosting Let's Dance! Style...   \n",
      "2      Calm before the 'glam' storm! üíãüíÑüíÖüèªüíÜüèºüíáüèºTomorrow...   \n",
      "3      üåºToday's look for QVC.. styled by @bydanienl #...   \n",
      "4      üíãHappy Weekend Lovelies ‚ù§ #weekend #yay #happy...   \n",
      "...                                                  ...   \n",
      "16534                   Everyday life in Tokyo\\n#RECO_ig   \n",
      "16535                   Everyday life in Tokyo\\n#RECO_ig   \n",
      "16536          Everyday life in Tokyo #film\\n#ÂÜô„É´„É≥„Åß„Åô #‰∏≠Â§ÆÁ∑ö   \n",
      "16537                   Everyday life in Tokyo\\n#RECO_ig   \n",
      "16538                          Tokyo in spring\\n#RECO_ig   \n",
      "\n",
      "                           date  numberLikes  \n",
      "0      2017-04-29T05:00:00.000Z        10047  \n",
      "1      2017-04-29T05:00:00.000Z        16781  \n",
      "2      2017-04-27T05:00:00.000Z        11227  \n",
      "3      2017-04-24T05:00:00.000Z        21539  \n",
      "4      2017-04-22T05:00:00.000Z        21054  \n",
      "...                         ...          ...  \n",
      "16534  2017-04-13T05:00:00.000Z        12240  \n",
      "16535  2017-04-12T05:00:00.000Z        11804  \n",
      "16536  2017-04-11T05:00:00.000Z         6814  \n",
      "16537  2017-04-10T05:00:00.000Z        13860  \n",
      "16538  2017-04-09T05:00:00.000Z        14921  \n",
      "\n",
      "[16539 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = \"profiles\"\n",
    "\n",
    "# Initialize empty lists to store the extracted data\n",
    "alias_list = []\n",
    "url_image_list = []\n",
    "is_video_list = []\n",
    "multiple_image_list = []\n",
    "tags_list = []\n",
    "mentions_list = []\n",
    "description_list = []\n",
    "date_list = []\n",
    "number_likes_list = []\n",
    "\n",
    "# Iterate over the JSON files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        # Read the JSON file with UTF-8 encoding\n",
    "        with open(os.path.join(folder_path, filename), encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Extract the alias\n",
    "        alias = data.get(\"alias\")\n",
    "        \n",
    "        # Extract the posts\n",
    "        posts = data.get(\"posts\", [])\n",
    "        for post in posts:\n",
    "            url_image = post.get(\"urlImage\")\n",
    "            is_video = post.get(\"isVideo\")\n",
    "            multiple_image = post.get(\"multipleImage\")\n",
    "            tags = post.get(\"tags\")\n",
    "            mentions = post.get(\"mentions\")\n",
    "            description = post.get(\"description\")\n",
    "            date = post.get(\"date\")\n",
    "            number_likes = post.get(\"numberLikes\")\n",
    "            \n",
    "            # Append the data to the respective lists\n",
    "            alias_list.append(alias)\n",
    "            url_image_list.append(url_image)\n",
    "            is_video_list.append(is_video)\n",
    "            multiple_image_list.append(multiple_image)\n",
    "            tags_list.append(tags)\n",
    "            mentions_list.append(mentions)\n",
    "            description_list.append(description)\n",
    "            date_list.append(date)\n",
    "            number_likes_list.append(number_likes)\n",
    "\n",
    "# Create the data frame\n",
    "data = {\n",
    "    \"alias\": alias_list,\n",
    "    \"urlImage\": url_image_list,\n",
    "    \"isVideo\": is_video_list,\n",
    "    \"multipleImage\": multiple_image_list,\n",
    "    \"tags\": tags_list,\n",
    "    \"mentions\": mentions_list,\n",
    "    \"description\": description_list,\n",
    "    \"date\": date_list,\n",
    "    \"numberLikes\": number_likes_list\n",
    "}\n",
    "posts_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the data frame\n",
    "print(posts_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average number of likes per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  alias  numberPosts  numberFollowers  numberFollowing  \\\n",
      "0            1misssmeis          988           720979              233   \n",
      "1                3ala2o          938           792886              466   \n",
      "2                   433         6009         14545102              433   \n",
      "3        6senseofficial         3324           243094                0   \n",
      "4               7ikhals         1444           219458              221   \n",
      "..                  ...          ...              ...              ...   \n",
      "973             _ingo_1          422           149566              127   \n",
      "974  _mariannejacobsen_         1593           189279              290   \n",
      "975             _picolo          776           927457              566   \n",
      "976          _tinamaria          821           160393              730   \n",
      "977              _tuck4         1623           139150              246   \n",
      "\n",
      "                                               website  average_likes  \n",
      "0                                    www.sylviemeis.de   23400.941176  \n",
      "1                  www.youtube.com/watch?v=MXkqzeIlhSQ    9300.058824  \n",
      "2                                    onelink.to/q6w524  310683.647059  \n",
      "3                      www.facebook.com/6senseofficial    9453.941176  \n",
      "4                                 instagram.com/ikhals    1074.352941  \n",
      "..                                                 ...            ...  \n",
      "973                                               None    2133.588235  \n",
      "974                          www.delicate-photoart.com    2834.882353  \n",
      "975                             www.patreon.com/picolo   81758.764706  \n",
      "976  jewelrybyad.com/da/jewelry-for-a-good-cause-20...    4076.352941  \n",
      "977                                   takashiyasui.com   10355.294118  \n",
      "\n",
      "[978 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Group posts_df by alias and calculate the average numberLikes\n",
    "average_likes = posts_df.groupby('alias')['numberLikes'].mean()\n",
    "\n",
    "# Add the average_likes column to profiles_df\n",
    "profiles_df['average_likes'] = profiles_df['alias'].map(average_likes)\n",
    "\n",
    "# Display the updated profiles_df\n",
    "print(profiles_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(747, 7)\n",
      "(12697, 10)\n"
     ]
    }
   ],
   "source": [
    "#filtering, such that\n",
    "#numberFollowers < 1.000.000\n",
    "#average_likes  < 200.000\n",
    "profiles_df = profiles_df[(profiles_df['numberFollowers'] < 1000000) & (profiles_df['average_likes'] < 200000)]\n",
    "print(profiles_df.shape)\n",
    "\n",
    "#apply filters also to posts_df\n",
    "posts_df = posts_df[posts_df['alias'].isin(profiles_df['alias'])]\n",
    "print(posts_df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing profiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other       576\n",
       "None         87\n",
       "Facebook     33\n",
       "Youtube      28\n",
       "Blog         19\n",
       "Twitter       3\n",
       "Music         1\n",
       "Name: website_category, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assigning categories based on the website\n",
    "def categorize_website(website):\n",
    "    if pd.isnull(website):\n",
    "        return 'None'\n",
    "    elif 'youtube' in website.lower():\n",
    "        return 'Youtube'\n",
    "    elif 'facebook' in website.lower():\n",
    "        return 'Facebook'\n",
    "    elif 'twitter' in website.lower():\n",
    "        return 'Twitter'\n",
    "    elif 'blog' in website.lower():\n",
    "        return 'Blog'\n",
    "    elif 'music' in website.lower() or 'spotify' in website.lower():\n",
    "        return 'Music'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "profiles_df['website_category'] = profiles_df['website'].apply(categorize_website)\n",
    "\n",
    "profiles_df['website_category'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing day of the week\n",
    "posts_df['date'] = pd.to_datetime(posts_df['date'])\n",
    "posts_df['weekday'] = posts_df['date'].dt.strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1272\n",
       "9     1271\n",
       "5     1271\n",
       "6     1270\n",
       "4     1270\n",
       "10    1269\n",
       "8     1269\n",
       "3     1269\n",
       "7     1268\n",
       "2     1268\n",
       "Name: numberLikesCategory, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorizing into 10 equally sized groups based on numberLikes\n",
    "#Category 10 are the 10% of posts with the highest likes\n",
    "#Category 1 are the 10% with the lowest likes\n",
    "\n",
    "# Sort the DataFrame by numberLikes in descending order\n",
    "posts_df = posts_df.sort_values('numberLikes', ascending=False)\n",
    "\n",
    "# Calculate the quantiles for the groups\n",
    "quantiles = pd.qcut(posts_df['numberLikes'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Assign the group numbers to the numberLikesCategory column\n",
    "posts_df['numberLikesCategory'] = quantiles + 1  # Add 1 to make the group numbers start from 1 instead of 0\n",
    "\n",
    "posts_df['numberLikesCategory'].value_counts()\n",
    "#sorted_df.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anwender\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Remove punctuation using regular expressions\n",
    "    no_punct = re.sub('['+string.punctuation+']', '', text)\n",
    "    return no_punct\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Remove stopwords using NLTK corpus\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    no_stopwords = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    return no_stopwords\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Convert emojis to textual representation and remove them\n",
    "    no_emojis = emoji.demojize(text)\n",
    "    no_emojis = re.sub('(:[a-z_-]+:)', ' ', no_emojis)\n",
    "    return no_emojis\n",
    "\n",
    "posts_df['descriptionProcessed'] = posts_df['description'].apply(remove_punctuation)\n",
    "posts_df['descriptionProcessed'] = posts_df['descriptionProcessed'].apply(remove_stopwords)\n",
    "posts_df['descriptionProcessed'] = posts_df['descriptionProcessed'].apply(remove_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12697, 500)\n",
      "(12697, 13)\n"
     ]
    }
   ],
   "source": [
    "#by default the vectorizer conerts the text to lower case and uses word-level tokenization\n",
    "# Create an instance of CountVectorizer with max_features set to 500 (this is what they did in the tds implementation)\n",
    "vec = CountVectorizer(max_features=500)\n",
    "\n",
    "\n",
    "# Transform the \"descriptionProcessed\" column into a matrix of token counts\n",
    "description_counts = vec.fit_transform(posts_df['descriptionProcessed'])\n",
    "\n",
    "# Convert the matrix to an array\n",
    "description_counts_array = description_counts.toarray()\n",
    "\n",
    "df = pd.DataFrame(data=description_counts_array,columns = vec.get_feature_names_out())\n",
    "print(df.shape)\n",
    "print(posts_df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en         9277\n",
       "es          479\n",
       "Unknown     406\n",
       "pt          321\n",
       "ru          248\n",
       "fr          208\n",
       "it          199\n",
       "de          147\n",
       "tr          130\n",
       "ar          121\n",
       "id          117\n",
       "no          107\n",
       "af          102\n",
       "ca           80\n",
       "et           72\n",
       "so           71\n",
       "tl           61\n",
       "nl           60\n",
       "cy           56\n",
       "fi           49\n",
       "ro           43\n",
       "sv           41\n",
       "pl           40\n",
       "da           35\n",
       "th           30\n",
       "vi           26\n",
       "fa           25\n",
       "ko           20\n",
       "ja           18\n",
       "sw           18\n",
       "sl           13\n",
       "bg           11\n",
       "sk           11\n",
       "mk           10\n",
       "hr            9\n",
       "sq            8\n",
       "hu            8\n",
       "zh-tw         5\n",
       "lt            5\n",
       "lv            5\n",
       "cs            2\n",
       "uk            2\n",
       "zh-cn         1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Assuming 'description' is the column name in your DataFrame\n",
    "posts_df['language'] = posts_df['description'].apply(detect_language)\n",
    "\n",
    "\n",
    "posts_df['language'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
